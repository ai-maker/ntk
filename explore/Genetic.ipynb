{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithms\n",
    "\n",
    "A genetic algorithm (GA) is an evolutionary optimisation technique that is a variant of stochastic beam search, which involves several search points/states concurrently, and somehow combines their features according to their performance to generate better successor states. Thus, GA differs from approaches like gradient descent that only rely on the modification and evolution of a single state. GA belongs to a family of metaheuristics, which are algorithms designed to tackle ill-defined functions where a clear and definite objective is impossible to use. GA are adequate for black box search processes.\n",
    "\n",
    "In GA, each search state, aka individual, encodes the problem information, usually as a binary array. GA begins with a set of randomly generated states, called the population. Then, it iterates over the chain of evolution for a given number of rounds, described as follows:\n",
    "\n",
    "1. *Fitness evaluation*: each state is scored regarding some effectiveness criterion.\n",
    "2. *Selection*: states are randomly sampled with a specific probability according to their fitness value.\n",
    "3. *Crossover*: selected individuals are randomly shuffled or combined at a specific point.\n",
    "4. *Mutation*: child individuals may flip some of their bits (each one with independent probability).\n",
    "\n",
    "![Genetic Algorithm](files/gaevol.png)\n",
    "\n",
    "The advantage with GA comes from the ability of crossover to combine large blocks of bits (i.e., state information) that have evolved independently to perform a specific useful function. However, the successful use and application of GA requires careful engineering of the state representation and its encoding (in addition to the more common optimisation parameters like the population size or the number of evolution rounds). This has a deep impact on the performance of the algorithm.\n",
    "\n",
    "The suggested GA algorithm does not posit any similarity with real world reproductive systems, though. Is it reasonable to prevent inbreeding? In nature, close genetic relation results in disorders. Such issues are not discussed here, but they donâ€™t seem to have much of an impact for function optimisation purposes (in this particular case, mutation may add value here by creating a new individual).\n",
    "\n",
    "Finally, regarding the computational complexities of GA, the space complexity is given by the number of individuals in the population $O(n)$, and the time complexity is driven by the intermediate processes of the evolution chain, such as ranking or filtering the individuals according to their fitness value for sampling.\n",
    "\n",
    "\n",
    "## GA for Neural Network training\n",
    "\n",
    "Encoding problem state information in a genetic algorithm (GA) is one of the most cumbersome aspects of its deployment. GA deals with binary vectors, so this is the format that one must comply with in order to find optimum solutions with this evolutionary technique. And depending on the chosen strategy, the solution of the search process may be different, and/or the GA algorithm may take more or less time (and/or space) to reach it.\n",
    "\n",
    "One convenient way of applying GA to neural net training (i.e., a weight optimisation problem) is by flattening and concatenating the matrices that define a neural net to build a kind of genetic chain, although this strictly breaks the binary vector principle. Then, the squared error criterion needs to be used as the fitness function. This workaround to the encoding problem works, although the GA mainly recombines the values generated initially. Only the mutation process is able to generate new weight values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init J = 1.0653127588697033\n",
      "Training...\n",
      "GA epoch = 0, best J: 0.6578278478599298\n",
      "GA epoch = 1, best J: 0.6578278478599298\n",
      "GA epoch = 2, best J: 0.6552921266467195\n",
      "GA epoch = 3, best J: 0.6552921266467195\n",
      "GA epoch = 4, best J: 0.6439918103619849\n",
      "GA epoch = 5, best J: 0.6439918103619849\n",
      "GA epoch = 6, best J: 0.6431986638019384\n",
      "GA epoch = 7, best J: 0.6431986638019384\n",
      "GA epoch = 8, best J: 0.6431986638019384\n",
      "GA epoch = 9, best J: 0.6431986638019384\n",
      "Testing...\n",
      "J = 0.9316762642571648\n"
     ]
    }
   ],
   "source": [
    "import NeuralNetwork\n",
    "from sklearn import datasets as dset\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "iris = dset.load_iris()\n",
    "t = []\n",
    "for i in iris.target:\n",
    "        if i == 0:\n",
    "                t.append([1,0,0])\n",
    "        elif i == 1:\n",
    "                t.append([0,1,0])\n",
    "        else:\n",
    "                t.append([0,0,1])\n",
    "\n",
    "y = np.array(t)\n",
    "X = iris.data\n",
    "\n",
    "sx,sy = shuffle(X,y)\n",
    "\n",
    "cutoff = 125\n",
    "\n",
    "nn = NeuralNetwork.MLP([4,2,3])\n",
    "tcost = NeuralNetwork.MLP_Cost(nn, sx[cutoff:], y[cutoff:], 0.0)\n",
    "print(\"Init J = \" + str(tcost))\n",
    "\n",
    "# 10 rounds of evolution with 100 individuals\n",
    "print(\"Training...\")\n",
    "nn = NeuralNetwork.MLP_GA([4,2,3], sx[:cutoff], y[:cutoff], 10, 100)\n",
    "print(\"Testing...\")\n",
    "tcost = NeuralNetwork.MLP_Cost(nn, sx[cutoff:], y[cutoff:], 0.0)\n",
    "print(\"J = \" + str(tcost))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
